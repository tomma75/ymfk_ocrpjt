# YOKOGAWA OCR 시스템 모델 상세 분석

## 📚 목차
1. [시스템 개요](#시스템-개요)
2. [사용되는 머신러닝 모델들](#사용되는-머신러닝-모델들)
3. [모델별 상세 특성](#모델별-상세-특성)
4. [앙상블 구조 및 결합 방식](#앙상블-구조-및-결합-방식)
5. [데이터 처리 파이프라인](#데이터-처리-파이프라인)
6. [학습 과정](#학습-과정)
7. [예측 과정](#예측-과정)
8. [초보자를 위한 설명](#초보자를-위한-설명)

---

## 시스템 개요

YOKOGAWA OCR 시스템은 3단계 계층 구조로 설계된 고급 OCR 라벨링 시스템입니다:

```
┌─────────────────────────────────────┐
│     Model Integration Service       │ ← 최상위 통합 계층
├─────────────────────────────────────┤
│  Hybrid Model │ Advanced │  Basic   │ ← 중간 모델 계층
├─────────────────────────────────────┤
│  ML Models (RF, XGB, LGBM, CRF)    │ ← 기반 알고리즘 계층
└─────────────────────────────────────┘
```

### 주요 서비스 파일
- `model_integration_service.py`: 모든 모델을 통합 관리
- `hybrid_ocr_labeler.py`: 최신 하이브리드 모델 (95% 정확도 목표)
- `advanced_model_service.py`: 고급 앙상블 모델
- `model_service.py`: 기본 규칙 기반 모델

---

## 사용되는 머신러닝 모델들

### 1. Random Forest (RF)
- **한국어 설명**: 랜덤 포레스트
- **쉬운 설명**: 여러 개의 의사결정 나무를 만들어서 다수결로 결정하는 방식
- **비유**: 중요한 결정을 할 때 여러 전문가에게 물어보고 가장 많이 나온 의견을 따르는 것과 같음

### 2. XGBoost (XGB)
- **한국어 설명**: 익스트림 그래디언트 부스팅
- **쉬운 설명**: 틀린 부분을 계속 개선하면서 학습하는 방식
- **비유**: 시험 문제를 틀렸을 때 그 부분을 집중적으로 공부하는 것과 같음

### 3. LightGBM (LGBM)
- **한국어 설명**: 라이트 그래디언트 부스팅 머신
- **쉬운 설명**: XGBoost와 비슷하지만 더 빠르고 효율적
- **비유**: 효율적인 학습법을 사용해서 더 빨리 배우는 것과 같음

### 4. CRF (Conditional Random Fields)
- **한국어 설명**: 조건부 랜덤 필드
- **쉬운 설명**: 문맥을 고려해서 순서가 있는 데이터를 분석
- **비유**: 문장에서 단어의 의미를 앞뒤 문맥으로 파악하는 것과 같음

### 5. Gradient Boosting
- **한국어 설명**: 그래디언트 부스팅
- **쉬운 설명**: 약한 학습기를 순차적으로 개선
- **비유**: 실수를 통해 계속 발전하는 학습 과정

---

## 모델별 상세 특성

### HybridOCRLabeler (최상위 모델)
```python
# 모델 구성
- RandomForestClassifier(n_estimators=200, max_depth=20)
- XGBClassifier(n_estimators=200, max_depth=10, learning_rate=0.1)
- LGBMClassifier(n_estimators=200, num_leaves=31, learning_rate=0.1)
- CRF(algorithm='lbfgs', c1=0.1, c2=0.1)

# 앙상블 가중치
- RF: 20%
- XGBoost: 30%
- LightGBM: 30%
- CRF: 20%
```

**특징**:
- 95% 이상의 정확도 목표
- 4개 모델의 예측을 가중 평균으로 결합
- 문서 전체의 문맥을 고려

### AdvancedModelService (고급 모델)
```python
# 앙상블 구성
- RandomForestClassifier × 3 (다른 파라미터)
- GradientBoostingClassifier × 2

# 특수 기능
- 템플릿 매칭
- 레이아웃 분석
- 관계성 분석
```

**특징**:
- 문서 구조 이해 (헤더, 본문, 푸터)
- 템플릿 기반 예측 보정
- 엔티티 간 관계 분석

### BasicModelService (기본 모델)
- 규칙 기반 라벨링
- 키워드 매칭
- 위치 기반 규칙

---

## 앙상블 구조 및 결합 방식

### 앙상블이란?
**쉬운 설명**: 여러 모델의 예측을 합쳐서 더 정확한 결과를 만드는 방법

### 결합 과정
```
입력 텍스트 "2024-08-27"
    ↓
┌──────────┬──────────┬──────────┬──────────┐
│    RF    │   XGB    │   LGBM   │   CRF    │
│  날짜    │  날짜    │  기타    │  날짜    │
│  (85%)   │  (92%)   │  (60%)   │  (88%)   │
└──────────┴──────────┴──────────┴──────────┘
    ↓         ↓          ↓          ↓
    20%      30%        30%        20%  (가중치)
    ↓         ↓          ↓          ↓
    17%   +  27.6%   +  18%    +  17.6% = 80.2%
                    ↓
            최종 예측: "날짜" (80.2% 신뢰도)
```

### 투표 방식
1. **가중 투표 (Weighted Voting)**: 각 모델의 예측에 가중치를 곱해서 합산
2. **다수결 (Majority Voting)**: 가장 많이 예측된 라벨 선택
3. **신뢰도 기반**: 각 모델의 신뢰도를 고려

---

## 데이터 처리 파이프라인

### 특징 추출 과정

```
OCR 텍스트 데이터
    ↓
1. 위치 특징 추출
   - 좌표 정규화 (x, y, width, height)
   - 사분면 정보 (1~4)
   - 영역 정보 (header/body/footer)
   
2. 텍스트 특징 추출
   - 길이, 숫자 비율, 특수문자
   - 패턴 매칭 (날짜, 이메일, 전화번호 등)
   - TF-IDF 벡터화
   
3. 관계성 특징 추출
   - 같은 행/열의 엔티티 수
   - 이웃 엔티티까지의 거리
   - 상대적 위치 정보
    ↓
특징 벡터 (숫자 배열)
```

### 특징 벡터 예시
```python
# 실제 추출되는 특징들 (총 50+ 차원)
[
    0.15,    # x 좌표 정규화
    0.23,    # y 좌표 정규화
    0.08,    # 너비 정규화
    0.03,    # 높이 정규화
    1,       # 사분면 (1=좌상단)
    2,       # 영역 (2=본문)
    10,      # 텍스트 길이
    0.8,     # 숫자 비율
    1,       # 날짜 패턴 매칭 여부
    3,       # 같은 행 엔티티 수
    ...      # 기타 특징들
]
```

---

## 학습 과정

### 1단계: 데이터 준비
```python
# v2 라벨 파일 로드
labels_v2/
  ├── 20250811_174447_..._label_v2.json
  ├── 20250811_174448_..._label_v2.json
  └── ...

# 각 파일 구조
{
    "entities": [
        {
            "entity_id": "ent_001",
            "bbox": {"x": 100, "y": 200, "width": 150, "height": 30},
            "text": {"value": "2024-08-27", "confidence": 0.95},
            "label": {"primary": "date", "confidence": 0.9}
        }
    ]
}
```

### 2단계: 특징 추출
- 각 엔티티에서 50개 이상의 특징 추출
- 숫자 특징과 텍스트 특징 분리

### 3단계: 모델 학습
```python
# 각 모델별 학습
for model in [rf, xgb, lgbm, crf]:
    model.fit(X_features, y_labels)
    
# 교차 검증 (5-fold)
scores = cross_val_score(model, X, y, cv=5)
```

### 4단계: 평가 및 저장
- 정확도, 정밀도, 재현율 계산
- 모델 파일 저장 (.pkl 형식)

---

## 예측 과정

### 실시간 예측 플로우

```
새로운 OCR 결과
    ↓
1. 엔티티 변환
   OCR 결과 → Entity 객체
    ↓
2. 특징 추출
   위치, 텍스트, 관계성 특징
    ↓
3. 모델별 예측
   ┌─────────────────────┐
   │ RF  → 예측 + 신뢰도 │
   │ XGB → 예측 + 신뢰도 │
   │ LGBM→ 예측 + 신뢰도 │
   │ CRF → 예측 + 신뢰도 │
   └─────────────────────┘
    ↓
4. 앙상블 결합
   가중 평균 계산
    ↓
5. 템플릿 보정 (선택적)
   알려진 문서 형식과 비교
    ↓
6. 최종 결과
   {
     "label": "date",
     "confidence": 0.85,
     "model_used": "hybrid"
   }
```

### 우선순위
1. **Hybrid Model** (최우선)
2. **Advanced Model** (차선)
3. **Basic Model** (폴백)

---

## 초보자를 위한 설명

### 🤖 머신러닝이란?
컴퓨터가 데이터를 보고 스스로 패턴을 학습하는 것입니다.

**예시**: 
- 사람: "이것은 날짜야" 라고 100개의 예시를 보여줌
- 컴퓨터: 날짜의 특징을 스스로 학습 (숫자-하이픈-숫자 패턴)
- 결과: 새로운 텍스트를 보고 날짜인지 스스로 판단

### 🎯 왜 여러 모델을 사용하나요?

**일상 생활 비유**:
중요한 병을 진단할 때 여러 의사에게 의견을 구하는 것과 같습니다.
- 의사 A (Random Forest): 종합적으로 판단
- 의사 B (XGBoost): 이전 사례를 참고해서 판단
- 의사 C (LightGBM): 빠르고 효율적으로 판단
- 의사 D (CRF): 전후 맥락을 보고 판단

→ 4명의 의견을 종합하면 더 정확한 진단 가능!

### 📊 신뢰도란?
모델이 자신의 예측에 대해 얼마나 확신하는지를 나타내는 숫자입니다.
- 95% 신뢰도: "거의 확실해요!"
- 70% 신뢰도: "아마 맞을 거예요"
- 40% 신뢰도: "확실하지 않아요"

### 🔄 학습 과정 쉽게 이해하기

1. **준비**: 정답이 표시된 문서 100개 준비
2. **학습**: 컴퓨터가 패턴 찾기
   - "날짜는 보통 숫자와 하이픈이 있어"
   - "주문번호는 10자리 숫자야"
   - "회사명은 보통 문서 상단에 있어"
3. **테스트**: 새 문서로 실력 확인
4. **개선**: 틀린 부분 다시 학습

### 💡 특징(Feature)이란?
컴퓨터가 판단할 때 보는 정보들입니다.

**사람이 "2024-08-27"을 볼 때**:
- "숫자가 있네" ✓
- "하이픈이 있네" ✓
- "날짜 형식이네" ✓

**컴퓨터가 보는 특징**:
- text_length: 10
- has_digits: true
- has_dash: true
- matches_date_pattern: true
- x_position: 0.15
- y_position: 0.23

---

## 성능 및 목표

### 현재 성능
- **Hybrid Model**: ~95% 목표 정확도
- **Advanced Model**: ~90% 정확도
- **Basic Model**: ~75% 정확도

### 개선 방향
1. 더 많은 학습 데이터 수집
2. 특징 엔지니어링 개선
3. 모델 하이퍼파라미터 튜닝
4. 도메인별 특화 모델 개발

---

## 실제 사용 예시

### 코드에서 모델 사용
```python
# 1. 서비스 초기화
service = ModelIntegrationService(config, logger)

# 2. 모델 학습
service.train_models()

# 3. 예측
result = service.predict_labels(image_path, ocr_results)

# 결과 구조
{
    'model_used': 'hybrid',  # 사용된 모델
    'predictions': [
        {
            'entity_id': 'ent_001',
            'text': '2024-08-27',
            'label': 'date',
            'confidence': 0.92
        }
    ],
    'confidence': 0.85  # 전체 신뢰도
}
```

### 웹 인터페이스에서
1. 문서 업로드
2. OCR 수행
3. 자동 라벨 제안 (모델 예측)
4. 사용자 확인 및 수정
5. 수정된 데이터로 재학습

---

## 파일 구조

```
services/
├── model_integration_service.py  # 통합 관리
│   ├── BasicModel
│   ├── AdvancedModel
│   └── HybridModel
│
├── hybrid_ocr_labeler.py        # 최신 하이브리드
│   ├── RandomForest
│   ├── XGBoost
│   ├── LightGBM
│   └── CRF
│
└── advanced_model_service.py    # 고급 모델
    ├── LayoutAnalyzer
    ├── RelationshipAnalyzer
    └── TemplateMatchin
```

---

## 자주 묻는 질문 (FAQ)

### Q: 왜 정확도가 100%가 아닌가요?
A: 실제 문서는 매우 다양하고 복잡합니다. 손글씨, 흐릿한 스캔, 특이한 레이아웃 등 예외 상황이 많아 100% 정확도는 현실적으로 불가능합니다.

### Q: 어떤 모델이 가장 좋나요?
A: 상황에 따라 다릅니다:
- **정확도 우선**: Hybrid Model
- **속도 우선**: Basic Model
- **균형**: Advanced Model

### Q: 학습에 얼마나 걸리나요?
A: 데이터 양에 따라 다르지만:
- 100개 문서: ~1분
- 1000개 문서: ~10분
- 10000개 문서: ~1시간

### Q: 새로운 라벨 타입을 추가할 수 있나요?
A: 네, 가능합니다. v2 라벨 형식으로 새 라벨을 추가하고 재학습하면 됩니다.

---

## 마무리

이 문서는 YOKOGAWA OCR 시스템의 머신러닝 모델을 상세히 설명합니다. 
추가 질문이나 설명이 필요한 부분이 있다면 언제든 문의해주세요!

**작성일**: 2025-08-27  
**버전**: 1.0.0