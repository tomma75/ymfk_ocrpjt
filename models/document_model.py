#!/usr/bin/env python3
"""
YOKOGAWA OCR ë°ì´í„° ì¤€ë¹„ í”„ë¡œì íŠ¸ - ë¬¸ì„œ ëª¨ë¸ ëª¨ë“ˆ

ì´ ëª¨ë“ˆì€ ë¬¸ì„œ ë°ì´í„°ë¥¼ í‘œí˜„í•˜ê³  ê´€ë¦¬í•˜ëŠ” ëª¨ë¸ í´ë˜ìŠ¤ë“¤ì„ ì •ì˜í•©ë‹ˆë‹¤.
PDF íŒŒì¼, ì´ë¯¸ì§€ íŒŒì¼ ë“±ì˜ ë¬¸ì„œ ë°ì´í„°ë¥¼ ì¶”ìƒí™”í•˜ì—¬ ì²˜ë¦¬í•©ë‹ˆë‹¤.

ì‘ì„±ì: YOKOGAWA OCR ê°œë°œíŒ€
ì‘ì„±ì¼: 2025-07-18
"""

import os
import json
import hashlib
from pathlib import Path
from datetime import datetime
from typing import Any, Dict, List, Optional, Union, Tuple
from dataclasses import dataclass, field
from enum import Enum
import uuid

from core.base_classes import BaseModel
from core.exceptions import (
    ValidationError,
    FileAccessError,
    FileFormatError,
    ProcessingError,
    DataIntegrityError,
)
from config.constants import (
    SUPPORTED_FILE_FORMATS,
    PDF_FILE_EXTENSIONS,
    IMAGE_FILE_EXTENSIONS,
    DEFAULT_IMAGE_RESOLUTION,
    MAX_FILE_SIZE_MB,
    TEXT_MIN_LENGTH,
    TEXT_MAX_LENGTH,
)


class DocumentType(Enum):
    """ë¬¸ì„œ íƒ€ì… ì—´ê±°í˜•"""

    PDF = "pdf"
    IMAGE = "image"
    UNKNOWN = "unknown"


class DocumentStatus(Enum):
    """ë¬¸ì„œ ì²˜ë¦¬ ìƒíƒœ ì—´ê±°í˜•"""

    PENDING = "pending"
    PROCESSING = "processing"
    COMPLETED = "completed"
    FAILED = "failed"
    VALIDATED = "validated"


class PageType(Enum):
    """í˜ì´ì§€ íƒ€ì… ì—´ê±°í˜•"""

    COVER = "cover"
    CONTENT = "content"
    APPENDIX = "appendix"
    BLANK = "blank"


# ====================================================================================
# 1. ë¬¸ì„œ ë©”íƒ€ë°ì´í„° í´ë˜ìŠ¤
# ====================================================================================


@dataclass
class DocumentMetadata:
    """
    ë¬¸ì„œ ë©”íƒ€ë°ì´í„° í´ë˜ìŠ¤

    íŒŒì¼ ì†ì„± ë° ë¬¸ì„œ ì •ë³´ë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤.
    """

    # íŒŒì¼ ì •ë³´
    file_path: str
    file_name: str
    file_size: int
    file_extension: str
    file_hash: str

    # ìƒì„±/ìˆ˜ì • ì •ë³´
    creation_date: datetime
    modification_date: datetime
    access_date: datetime

    # ë¬¸ì„œ ì†ì„±
    document_title: str = ""
    document_author: str = ""
    document_subject: str = ""
    document_keywords: str = ""
    document_creator: str = ""
    document_producer: str = ""

    # ê¸°ìˆ ì  ì •ë³´
    page_count: int = 0
    document_version: str = ""
    encryption_status: bool = False

    # ì¶”ê°€ ì†ì„±
    custom_properties: Dict[str, Any] = field(default_factory=dict)

    def __post_init__(self) -> None:
        """ì´ˆê¸°í™” í›„ ê²€ì¦"""
        self._validate_metadata()

    def _validate_metadata(self) -> None:
        """ë©”íƒ€ë°ì´í„° ê²€ì¦"""
        if not os.path.exists(self.file_path):
            raise FileAccessError(
                message=f"File not found: {self.file_path}", file_path=self.file_path
            )

        if self.file_size <= 0:
            raise ValidationError(
                message=f"Invalid file size: {self.file_size}",
                validation_type="file_size",
            )

        if self.file_extension not in SUPPORTED_FILE_FORMATS:
            raise FileFormatError(
                message=f"Unsupported file format: {self.file_extension}",
                file_path=self.file_path,
                expected_format=", ".join(SUPPORTED_FILE_FORMATS),
                actual_format=self.file_extension,
            )

    def to_dict(self) -> Dict[str, Any]:
        """ë©”íƒ€ë°ì´í„°ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return {
            "file_path": self.file_path,
            "file_name": self.file_name,
            "file_size": self.file_size,
            "file_extension": self.file_extension,
            "file_hash": self.file_hash,
            "creation_date": self.creation_date.isoformat(),
            "modification_date": self.modification_date.isoformat(),
            "access_date": self.access_date.isoformat(),
            "document_title": self.document_title,
            "document_author": self.document_author,
            "document_subject": self.document_subject,
            "document_keywords": self.document_keywords,
            "document_creator": self.document_creator,
            "document_producer": self.document_producer,
            "page_count": self.page_count,
            "document_version": self.document_version,
            "encryption_status": self.encryption_status,
            "custom_properties": self.custom_properties,
        }

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> "DocumentMetadata":
        """ë”•ì…”ë„ˆë¦¬ì—ì„œ ë©”íƒ€ë°ì´í„° ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
        return cls(
            file_path=data["file_path"],
            file_name=data["file_name"],
            file_size=data["file_size"],
            file_extension=data["file_extension"],
            file_hash=data["file_hash"],
            creation_date=datetime.fromisoformat(data["creation_date"]),
            modification_date=datetime.fromisoformat(data["modification_date"]),
            access_date=datetime.fromisoformat(data["access_date"]),
            document_title=data.get("document_title", ""),
            document_author=data.get("document_author", ""),
            document_subject=data.get("document_subject", ""),
            document_keywords=data.get("document_keywords", ""),
            document_creator=data.get("document_creator", ""),
            document_producer=data.get("document_producer", ""),
            page_count=data.get("page_count", 0),
            document_version=data.get("document_version", ""),
            encryption_status=data.get("encryption_status", False),
            custom_properties=data.get("custom_properties", {}),
        )

    def update_custom_property(self, key: str, value: Any) -> None:
        """ì‚¬ìš©ì ì •ì˜ ì†ì„± ì—…ë°ì´íŠ¸"""
        self.custom_properties[key] = value

    def get_custom_property(self, key: str, default: Any = None) -> Any:
        """ì‚¬ìš©ì ì •ì˜ ì†ì„± ì¡°íšŒ"""
        return self.custom_properties.get(key, default)


# ====================================================================================
# 2. í˜ì´ì§€ ì •ë³´ í´ë˜ìŠ¤
# ====================================================================================


@dataclass
class PageInfo:
    """
    í˜ì´ì§€ ì •ë³´ í´ë˜ìŠ¤

    ë¬¸ì„œì˜ ê°œë³„ í˜ì´ì§€ ì •ë³´ë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤.
    """

    # ê¸°ë³¸ ì •ë³´
    page_number: int
    page_type: PageType = PageType.CONTENT

    # ë¬¼ë¦¬ì  ì†ì„±
    page_width: int = 0
    page_height: int = 0
    page_rotation: int = 0
    page_resolution: int = DEFAULT_IMAGE_RESOLUTION

    # ì»¨í…ì¸  ì •ë³´
    has_text: bool = False
    has_images: bool = False
    has_tables: bool = False
    has_forms: bool = False

    # í…ìŠ¤íŠ¸ ì •ë³´
    text_content: str = ""
    text_length: int = 0
    text_language: str = "ko"

    # ì´ë¯¸ì§€ ì •ë³´
    image_count: int = 0
    image_paths: List[str] = field(default_factory=list)

    # í’ˆì§ˆ ì •ë³´
    quality_score: float = 0.0
    is_blank: bool = False
    has_noise: bool = False

    # ì²˜ë¦¬ ì •ë³´
    processing_time: float = 0.0
    processing_errors: List[str] = field(default_factory=list)

    def __post_init__(self) -> None:
        """ì´ˆê¸°í™” í›„ ê²€ì¦"""
        self._validate_page_info()
        self._calculate_derived_properties()

    def _validate_page_info(self) -> None:
        """í˜ì´ì§€ ì •ë³´ ê²€ì¦"""
        if self.page_number < 1:
            raise ValidationError(
                message=f"Invalid page number: {self.page_number}",
                validation_type="page_number",
            )

        if self.page_width < 0 or self.page_height < 0:
            raise ValidationError(
                message=f"Invalid page dimensions: {self.page_width}x{self.page_height}",
                validation_type="page_dimensions",
            )

    def _calculate_derived_properties(self) -> None:
        """íŒŒìƒ ì†ì„± ê³„ì‚°"""
        self.text_length = len(self.text_content)
        self.image_count = len(self.image_paths)
        self.is_blank = (
            not self.has_text
            and not self.has_images
            and not self.has_tables
            and not self.has_forms
        )

    def to_dict(self) -> Dict[str, Any]:
        """í˜ì´ì§€ ì •ë³´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return {
            "page_number": self.page_number,
            "page_type": self.page_type.value,
            "page_width": self.page_width,
            "page_height": self.page_height,
            "page_rotation": self.page_rotation,
            "page_resolution": self.page_resolution,
            "has_text": self.has_text,
            "has_images": self.has_images,
            "has_tables": self.has_tables,
            "has_forms": self.has_forms,
            "text_content": self.text_content,
            "text_length": self.text_length,
            "text_language": self.text_language,
            "image_count": self.image_count,
            "image_paths": self.image_paths,
            "quality_score": self.quality_score,
            "is_blank": self.is_blank,
            "has_noise": self.has_noise,
            "processing_time": self.processing_time,
            "processing_errors": self.processing_errors,
        }

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> "PageInfo":
        """ë”•ì…”ë„ˆë¦¬ì—ì„œ í˜ì´ì§€ ì •ë³´ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
        return cls(
            page_number=data["page_number"],
            page_type=PageType(data.get("page_type", "content")),
            page_width=data.get("page_width", 0),
            page_height=data.get("page_height", 0),
            page_rotation=data.get("page_rotation", 0),
            page_resolution=data.get("page_resolution", DEFAULT_IMAGE_RESOLUTION),
            has_text=data.get("has_text", False),
            has_images=data.get("has_images", False),
            has_tables=data.get("has_tables", False),
            has_forms=data.get("has_forms", False),
            text_content=data.get("text_content", ""),
            text_language=data.get("text_language", "ko"),
            image_paths=data.get("image_paths", []),
            quality_score=data.get("quality_score", 0.0),
            has_noise=data.get("has_noise", False),
            processing_time=data.get("processing_time", 0.0),
            processing_errors=data.get("processing_errors", []),
        )

    def add_image_path(self, image_path: str) -> None:
        """ì´ë¯¸ì§€ ê²½ë¡œ ì¶”ê°€"""
        if image_path not in self.image_paths:
            self.image_paths.append(image_path)
            self.image_count = len(self.image_paths)
            self.has_images = True

    def set_text_content(self, text: str) -> None:
        """í…ìŠ¤íŠ¸ ì»¨í…ì¸  ì„¤ì •"""
        self.text_content = text.strip()
        self.text_length = len(self.text_content)
        self.has_text = self.text_length > 0

    def add_processing_error(self, error: str) -> None:
        """ì²˜ë¦¬ ì˜¤ë¥˜ ì¶”ê°€"""
        self.processing_errors.append(error)

    def get_aspect_ratio(self) -> float:
        """í˜ì´ì§€ ì¢…íš¡ë¹„ ë°˜í™˜"""
        if self.page_height == 0:
            return 0.0
        return self.page_width / self.page_height

    def set_document_id(self, document_id: str) -> None:
        self.document_id = document_id

    def set_file_path(self, file_path: str) -> None:
        self.file_path = file_path

    def set_file_name(self, file_name: str) -> None:
        self.file_name = file_name

    def set_file_size(self, file_size: int) -> None:
        self.file_size = file_size


# ====================================================================================
# 3. ë¬¸ì„œ í†µê³„ í´ë˜ìŠ¤
# ====================================================================================


@dataclass
class DocumentStatistics:
    """
    ë¬¸ì„œ í†µê³„ ì •ë³´ í´ë˜ìŠ¤

    ë¬¸ì„œ ì „ì²´ì˜ í†µê³„ ì •ë³´ë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤.
    """

    # ê¸°ë³¸ í†µê³„
    total_pages: int = 0
    total_text_length: int = 0
    total_images: int = 0
    total_tables: int = 0
    total_forms: int = 0

    # í˜ì´ì§€ íƒ€ì…ë³„ í†µê³„
    cover_pages: int = 0
    content_pages: int = 0
    appendix_pages: int = 0
    blank_pages: int = 0

    # í’ˆì§ˆ í†µê³„
    average_quality_score: float = 0.0
    min_quality_score: float = 0.0
    max_quality_score: float = 0.0
    pages_with_noise: int = 0

    # ì²˜ë¦¬ í†µê³„
    total_processing_time: float = 0.0
    average_processing_time: float = 0.0
    pages_with_errors: int = 0
    total_errors: int = 0

    # ì–¸ì–´ í†µê³„
    detected_languages: Dict[str, int] = field(default_factory=dict)
    primary_language: str = ""

    def calculate_statistics(self, pages: List[PageInfo]) -> None:
        """í˜ì´ì§€ ì •ë³´ ëª©ë¡ì—ì„œ í†µê³„ ê³„ì‚°"""
        if not pages:
            return

        self.total_pages = len(pages)

        # ê¸°ë³¸ í†µê³„ ê³„ì‚°
        self.total_text_length = sum(page.text_length for page in pages)
        self.total_images = sum(page.image_count for page in pages)

        # í˜ì´ì§€ íƒ€ì…ë³„ í†µê³„
        type_counts = {}
        for page in pages:
            page_type = page.page_type.value
            type_counts[page_type] = type_counts.get(page_type, 0) + 1

        self.cover_pages = type_counts.get("cover", 0)
        self.content_pages = type_counts.get("content", 0)
        self.appendix_pages = type_counts.get("appendix", 0)
        self.blank_pages = sum(1 for page in pages if page.is_blank)

        # í’ˆì§ˆ í†µê³„
        quality_scores = [
            page.quality_score for page in pages if page.quality_score > 0
        ]
        if quality_scores:
            self.average_quality_score = sum(quality_scores) / len(quality_scores)
            self.min_quality_score = min(quality_scores)
            self.max_quality_score = max(quality_scores)

        self.pages_with_noise = sum(1 for page in pages if page.has_noise)

        # ì²˜ë¦¬ í†µê³„
        self.total_processing_time = sum(page.processing_time for page in pages)
        if self.total_pages > 0:
            self.average_processing_time = self.total_processing_time / self.total_pages

        self.pages_with_errors = sum(1 for page in pages if page.processing_errors)
        self.total_errors = sum(len(page.processing_errors) for page in pages)

        # ì–¸ì–´ í†µê³„
        language_counts = {}
        for page in pages:
            if page.text_language:
                language_counts[page.text_language] = (
                    language_counts.get(page.text_language, 0) + 1
                )

        self.detected_languages = language_counts
        if language_counts:
            self.primary_language = max(language_counts, key=language_counts.get)

    def to_dict(self) -> Dict[str, Any]:
        """í†µê³„ ì •ë³´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return {
            "total_pages": self.total_pages,
            "total_text_length": self.total_text_length,
            "total_images": self.total_images,
            "total_tables": self.total_tables,
            "total_forms": self.total_forms,
            "cover_pages": self.cover_pages,
            "content_pages": self.content_pages,
            "appendix_pages": self.appendix_pages,
            "blank_pages": self.blank_pages,
            "average_quality_score": self.average_quality_score,
            "min_quality_score": self.min_quality_score,
            "max_quality_score": self.max_quality_score,
            "pages_with_noise": self.pages_with_noise,
            "total_processing_time": self.total_processing_time,
            "average_processing_time": self.average_processing_time,
            "pages_with_errors": self.pages_with_errors,
            "total_errors": self.total_errors,
            "detected_languages": self.detected_languages,
            "primary_language": self.primary_language,
        }

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> "DocumentStatistics":
        """ë”•ì…”ë„ˆë¦¬ì—ì„œ í†µê³„ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
        return cls(
            total_pages=data.get("total_pages", 0),
            total_text_length=data.get("total_text_length", 0),
            total_images=data.get("total_images", 0),
            total_tables=data.get("total_tables", 0),
            total_forms=data.get("total_forms", 0),
            cover_pages=data.get("cover_pages", 0),
            content_pages=data.get("content_pages", 0),
            appendix_pages=data.get("appendix_pages", 0),
            blank_pages=data.get("blank_pages", 0),
            average_quality_score=data.get("average_quality_score", 0.0),
            min_quality_score=data.get("min_quality_score", 0.0),
            max_quality_score=data.get("max_quality_score", 0.0),
            pages_with_noise=data.get("pages_with_noise", 0),
            total_processing_time=data.get("total_processing_time", 0.0),
            average_processing_time=data.get("average_processing_time", 0.0),
            pages_with_errors=data.get("pages_with_errors", 0),
            total_errors=data.get("total_errors", 0),
            detected_languages=data.get("detected_languages", {}),
            primary_language=data.get("primary_language", ""),
        )


# ====================================================================================
# 4. ë©”ì¸ ë¬¸ì„œ ëª¨ë¸ í´ë˜ìŠ¤
# ====================================================================================


class DocumentModel(BaseModel):
    """
    ë¬¸ì„œ ëª¨ë¸ í´ë˜ìŠ¤

    PDF íŒŒì¼ì´ë‚˜ ì´ë¯¸ì§€ íŒŒì¼ì„ ì¶”ìƒí™”í•œ ë¬¸ì„œ ëª¨ë¸ì…ë‹ˆë‹¤.
    BaseModelì„ ìƒì†ë°›ì•„ í‘œì¤€ ëª¨ë¸ ì¸í„°í˜ì´ìŠ¤ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.
    """

    def __init__(
        self,
        file_path: str,
        metadata: Optional[DocumentMetadata] = None,
        document_type: Optional[DocumentType] = None,
    ):
        """
        DocumentModel ì´ˆê¸°í™”

        Args:
            file_path: ë¬¸ì„œ íŒŒì¼ ê²½ë¡œ
            metadata: ë¬¸ì„œ ë©”íƒ€ë°ì´í„° (ì—†ìœ¼ë©´ ìë™ ìƒì„±)
            document_type: ë¬¸ì„œ íƒ€ì… (ì—†ìœ¼ë©´ ìë™ ê°ì§€)
        """
        super().__init__()

        # ê¸°ë³¸ ì •ë³´
        self.file_path = file_path
        self.document_id = str(uuid.uuid4())
        self.document_type = document_type or self._detect_document_type(file_path)
        self.document_status = DocumentStatus.PENDING

        # ë©”íƒ€ë°ì´í„°
        self.metadata = metadata or self._extract_metadata(file_path)

        # í˜ì´ì§€ ì •ë³´
        self.pages: List[PageInfo] = []
        self.current_page_index = 0

        # í†µê³„ ì •ë³´
        self.statistics = DocumentStatistics()

        # ì–´ë…¸í…Œì´ì…˜ ê´€ë ¨
        self.annotations: List[Any] = []  # AnnotationModel ìˆœí™˜ ì˜ì¡´ì„± ë°©ì§€
        self.annotation_count = 0
        self.annotation_progress = 0.0

        # ì²˜ë¦¬ ì •ë³´
        self.processing_history: List[Dict[str, Any]] = []
        self.last_processed_time: Optional[datetime] = None
        self.processing_errors: List[str] = []

        # ê²€ì¦ ì •ë³´
        self.is_validated = False
        self.validation_errors: List[str] = []
        self.validation_warnings: List[str] = []

        # ì´ˆê¸° ê²€ì¦
        self._validate_initial_state()

    def _detect_document_type(self, file_path: str) -> DocumentType:
        """íŒŒì¼ ê²½ë¡œì—ì„œ ë¬¸ì„œ íƒ€ì… ê°ì§€"""
        file_extension = Path(file_path).suffix.lower()

        if file_extension in PDF_FILE_EXTENSIONS:
            return DocumentType.PDF
        elif file_extension in IMAGE_FILE_EXTENSIONS:
            return DocumentType.IMAGE
        else:
            return DocumentType.UNKNOWN

    def _extract_metadata(self, file_path: str) -> DocumentMetadata:
        """íŒŒì¼ì—ì„œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
        try:
            file_path = os.path.abspath(file_path)
            file_stat = os.stat(file_path)

            # íŒŒì¼ í•´ì‹œ ê³„ì‚°
            file_hash = self._calculate_file_hash(file_path)

            # ê¸°ë³¸ ë©”íƒ€ë°ì´í„° ìƒì„±
            metadata = DocumentMetadata(
                file_path=file_path,
                file_name=os.path.basename(file_path),
                file_size=file_stat.st_size,
                file_extension=Path(file_path).suffix.lower(),
                file_hash=file_hash,
                creation_date=datetime.fromtimestamp(file_stat.st_ctime),
                modification_date=datetime.fromtimestamp(file_stat.st_mtime),
                access_date=datetime.fromtimestamp(file_stat.st_atime),
            )

            # ë¬¸ì„œ íƒ€ì…ë³„ ì¶”ê°€ ì •ë³´ ì¶”ì¶œ
            if self.document_type == DocumentType.PDF:
                self._extract_pdf_metadata(metadata)
            elif self.document_type == DocumentType.IMAGE:
                self._extract_image_metadata(metadata)

            return metadata

        except Exception as e:
            raise ProcessingError(
                message=f"Failed to extract metadata from {file_path}: {str(e)}",
                processor_id=self.model_id,
                processing_stage="metadata_extraction",
                original_exception=e,
            )

    def _calculate_file_hash(self, file_path: str) -> str:
        """íŒŒì¼ í•´ì‹œ ê³„ì‚°"""
        try:
            hash_md5 = hashlib.md5()
            with open(file_path, "rb") as f:
                for chunk in iter(lambda: f.read(4096), b""):
                    hash_md5.update(chunk)
            return hash_md5.hexdigest()
        except Exception as e:
            raise ProcessingError(
                message=f"Failed to calculate file hash: {str(e)}", original_exception=e
            )

    def _extract_pdf_metadata(self, metadata: DocumentMetadata) -> None:
        """PDF ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
        try:
            # PDF ë¼ì´ë¸ŒëŸ¬ë¦¬ import (ì§€ì—° importë¡œ ì˜ì¡´ì„± ìµœì†Œí™”)
            import fitz  # PyMuPDF

            pdf_document = fitz.open(metadata.file_path)

            # í˜ì´ì§€ ìˆ˜ ì„¤ì •
            metadata.page_count = len(pdf_document)

            # ë¬¸ì„œ ì •ë³´ ì¶”ì¶œ
            pdf_metadata = pdf_document.metadata
            metadata.document_title = pdf_metadata.get("title", "")
            metadata.document_author = pdf_metadata.get("author", "")
            metadata.document_subject = pdf_metadata.get("subject", "")
            metadata.document_keywords = pdf_metadata.get("keywords", "")
            metadata.document_creator = pdf_metadata.get("creator", "")
            metadata.document_producer = pdf_metadata.get("producer", "")

            # ì•”í˜¸í™” ìƒíƒœ í™•ì¸
            metadata.encryption_status = pdf_document.needs_pass

            pdf_document.close()

        except ImportError:
            self.add_validation_error("PyMuPDF not available for PDF processing")
        except Exception as e:
            self.add_validation_error(f"PDF metadata extraction failed: {str(e)}")

    def _extract_image_metadata(self, metadata: DocumentMetadata) -> None:
        """ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
        try:
            # PIL ë¼ì´ë¸ŒëŸ¬ë¦¬ import (ì§€ì—° importë¡œ ì˜ì¡´ì„± ìµœì†Œí™”)
            from PIL import Image

            with Image.open(metadata.file_path) as img:
                # ì´ë¯¸ì§€ ì •ë³´
                metadata.custom_properties.update(
                    {
                        "image_format": img.format,
                        "image_mode": img.mode,
                        "image_size": img.size,
                        "image_has_transparency": img.mode in ("RGBA", "LA")
                        or "transparency" in img.info,
                    }
                )

                # EXIF ë°ì´í„° ì¶”ì¶œ
                if hasattr(img, "_getexif") and img._getexif():
                    exif_data = img._getexif()
                    metadata.custom_properties["exif_data"] = exif_data

                # ì´ë¯¸ì§€ëŠ” ë‹¨ì¼ í˜ì´ì§€ë¡œ ì²˜ë¦¬
                metadata.page_count = 1

        except ImportError:
            self.add_validation_error("PIL not available for image processing")
        except Exception as e:
            self.add_validation_error(f"Image metadata extraction failed: {str(e)}")

    def _validate_initial_state(self) -> None:
        """ì´ˆê¸° ìƒíƒœ ê²€ì¦"""
        if not os.path.exists(self.file_path):
            raise FileAccessError(
                message=f"File not found: {self.file_path}", file_path=self.file_path
            )

        if self.document_type == DocumentType.UNKNOWN:
            self.add_validation_error(
                f"Unknown document type for file: {self.file_path}"
            )

        # íŒŒì¼ í¬ê¸° ê²€ì¦
        file_size_mb = self.metadata.file_size / (1024 * 1024)
        if file_size_mb > MAX_FILE_SIZE_MB:
            raise ValidationError(
                message=f"File size ({file_size_mb:.2f} MB) exceeds maximum allowed size ({MAX_FILE_SIZE_MB} MB)",
                validation_type="file_size",
            )

    # BaseModel ì¶”ìƒ ë©”ì„œë“œ êµ¬í˜„
    def to_dict(self) -> Dict[str, Any]:
        """
        ë¬¸ì„œ ëª¨ë¸ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜

        Returns:
            Dict[str, Any]: ë¬¸ì„œ ëª¨ë¸ ë”•ì…”ë„ˆë¦¬
        """
        return {
            "document_id": self.document_id,
            "file_path": self.file_path,
            "document_type": self.document_type.value,
            "document_status": self.document_status.value,
            "metadata": self.metadata.to_dict(),
            "pages": [page.to_dict() for page in self.pages],
            "statistics": self.statistics.to_dict(),
            "annotation_count": self.annotation_count,
            "annotation_progress": self.annotation_progress,
            "processing_history": self.processing_history,
            "last_processed_time": (
                self.last_processed_time.isoformat()
                if self.last_processed_time
                else None
            ),
            "processing_errors": self.processing_errors,
            "is_validated": self.is_validated,
            "validation_errors": self.validation_errors,
            "validation_warnings": self.validation_warnings,
            "created_at": self.created_at.isoformat(),
            "updated_at": self.updated_at.isoformat(),
            "version": self.version,
        }

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> "DocumentModel":
        """
        ë”•ì…”ë„ˆë¦¬ì—ì„œ ë¬¸ì„œ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±

        Args:
            data: ë¬¸ì„œ ëª¨ë¸ ë°ì´í„° ë”•ì…”ë„ˆë¦¬

        Returns:
            DocumentModel: ë¬¸ì„œ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤
        """
        # ë©”íƒ€ë°ì´í„° ë³µì›
        metadata = DocumentMetadata.from_dict(data["metadata"])

        # ë¬¸ì„œ íƒ€ì… ë³µì›
        document_type = DocumentType(data["document_type"])

        # ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        instance = cls(
            file_path=data["file_path"], metadata=metadata, document_type=document_type
        )

        # ì¶”ê°€ ì†ì„± ë³µì›
        instance.document_id = data["document_id"]
        instance.document_status = DocumentStatus(data["document_status"])

        # í˜ì´ì§€ ì •ë³´ ë³µì›
        instance.pages = [PageInfo.from_dict(page_data) for page_data in data["pages"]]

        # í†µê³„ ì •ë³´ ë³µì›
        instance.statistics = DocumentStatistics.from_dict(data["statistics"])

        # ì–´ë…¸í…Œì´ì…˜ ì •ë³´ ë³µì›
        instance.annotation_count = data.get("annotation_count", 0)
        instance.annotation_progress = data.get("annotation_progress", 0.0)

        # ì²˜ë¦¬ ì •ë³´ ë³µì›
        instance.processing_history = data.get("processing_history", [])
        if data.get("last_processed_time"):
            instance.last_processed_time = datetime.fromisoformat(
                data["last_processed_time"]
            )
        instance.processing_errors = data.get("processing_errors", [])

        # ê²€ì¦ ì •ë³´ ë³µì›
        instance.is_validated = data.get("is_validated", False)
        instance.validation_errors = data.get("validation_errors", [])
        instance.validation_warnings = data.get("validation_warnings", [])

        return instance

    def validate(self) -> bool:
        """
        ë¬¸ì„œ ëª¨ë¸ ë°ì´í„° ìœ íš¨ì„± ê²€ì¦

        Returns:
            bool: ìœ íš¨ì„± ê²€ì¦ ê²°ê³¼
        """
        self.clear_validation_errors()

        try:
            # íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
            if not os.path.exists(self.file_path):
                self.add_validation_error(f"File not found: {self.file_path}")

            # ë©”íƒ€ë°ì´í„° ê²€ì¦
            if not self.metadata:
                self.add_validation_error("Document metadata is missing")

            # ë¬¸ì„œ íƒ€ì… ê²€ì¦
            if self.document_type == DocumentType.UNKNOWN:
                self.add_validation_error("Document type is unknown")

            # í˜ì´ì§€ ì •ë³´ ê²€ì¦
            if self.metadata.page_count > 0 and not self.pages:
                self.add_validation_error("Page information is missing")

            # í˜ì´ì§€ ë²ˆí˜¸ ì—°ì†ì„± ê²€ì¦
            if self.pages:
                expected_page_numbers = list(range(1, len(self.pages) + 1))
                actual_page_numbers = [page.page_number for page in self.pages]
                if actual_page_numbers != expected_page_numbers:
                    self.add_validation_error("Page numbers are not consecutive")

            # ì–´ë…¸í…Œì´ì…˜ ì¼ê´€ì„± ê²€ì¦
            if self.annotation_count != len(self.annotations):
                self.add_validation_error("Annotation count mismatch")

            # ì§„í–‰ë¥  ê²€ì¦
            if not (0.0 <= self.annotation_progress <= 1.0):
                self.add_validation_error("Invalid annotation progress value")

            # ê²€ì¦ ì™„ë£Œ í‘œì‹œ
            self.is_validated = len(self.validation_errors) == 0

            return self.is_validated

        except Exception as e:
            self.add_validation_error(f"Validation failed: {str(e)}")
            return False

    # ì¶”ê°€ ë©”ì„œë“œë“¤
    @classmethod
    def from_file_path(cls, file_path: str) -> "DocumentModel":
        """
        íŒŒì¼ ê²½ë¡œì—ì„œ ë¬¸ì„œ ëª¨ë¸ ìƒì„±

        Args:
            file_path: ë¬¸ì„œ íŒŒì¼ ê²½ë¡œ

        Returns:
            DocumentModel: ë¬¸ì„œ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤
        """
        return cls(file_path=file_path)

    def validate_document_format(self) -> bool:
        """
        ë¬¸ì„œ í˜•ì‹ ìœ íš¨ì„± ê²€ì¦

        Returns:
            bool: í˜•ì‹ ìœ íš¨ì„± ê²€ì¦ ê²°ê³¼
        """
        try:
            # íŒŒì¼ í™•ì¥ì ê²€ì¦
            if self.metadata.file_extension not in SUPPORTED_FILE_FORMATS:
                return False

            # íŒŒì¼ í¬ê¸° ê²€ì¦
            file_size_mb = self.metadata.file_size / (1024 * 1024)
            if file_size_mb > MAX_FILE_SIZE_MB:
                return False

            # ë¬¸ì„œ íƒ€ì…ë³„ í˜•ì‹ ê²€ì¦
            if self.document_type == DocumentType.PDF:
                return self._validate_pdf_format()
            elif self.document_type == DocumentType.IMAGE:
                return self._validate_image_format()

            return True

        except Exception as e:
            self.add_validation_error(f"Format validation failed: {str(e)}")
            return False

    def _validate_pdf_format(self) -> bool:
        """PDF í˜•ì‹ ê²€ì¦"""
        try:
            import fitz

            pdf_document = fitz.open(self.file_path)
            is_valid = len(pdf_document) > 0
            pdf_document.close()
            return is_valid
        except Exception:
            return False

    def _validate_image_format(self) -> bool:
        """ì´ë¯¸ì§€ í˜•ì‹ ê²€ì¦"""
        try:
            from PIL import Image

            with Image.open(self.file_path) as img:
                img.verify()
            return True
        except Exception:
            return False

    def extract_text_content(self) -> str:
        """
        ë¬¸ì„œì—ì„œ í…ìŠ¤íŠ¸ ì»¨í…ì¸  ì¶”ì¶œ

        Returns:
            str: ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ë‚´ìš©
        """
        if not self.pages:
            return ""

        text_content = []
        for page in self.pages:
            if page.text_content:
                text_content.append(page.text_content)

        return "\n\n".join(text_content)

    def get_page_count(self) -> int:
        """
        í˜ì´ì§€ ìˆ˜ ë°˜í™˜

        Returns:
            int: í˜ì´ì§€ ìˆ˜
        """
        return self.metadata.page_count

    def add_page(self, page_info: PageInfo) -> None:
        """
        í˜ì´ì§€ ì •ë³´ ì¶”ê°€

        Args:
            page_info: ì¶”ê°€í•  í˜ì´ì§€ ì •ë³´
        """
        self.pages.append(page_info)
        self.metadata.page_count = len(self.pages)
        self.statistics.calculate_statistics(self.pages)
        self._updated_at = datetime.now()
        self._version += 1

    def get_page(self, page_number: int) -> Optional[PageInfo]:
        """
        íŠ¹ì • í˜ì´ì§€ ì •ë³´ ì¡°íšŒ

        Args:
            page_number: í˜ì´ì§€ ë²ˆí˜¸ (1ë¶€í„° ì‹œì‘)

        Returns:
            Optional[PageInfo]: í˜ì´ì§€ ì •ë³´ (ì—†ìœ¼ë©´ None)
        """
        for page in self.pages:
            if page.page_number == page_number:
                return page
        return None

    def add_annotation(self, annotation: Any) -> None:
        """
        ì–´ë…¸í…Œì´ì…˜ ì¶”ê°€

        Args:
            annotation: ì¶”ê°€í•  ì–´ë…¸í…Œì´ì…˜ ê°ì²´
        """
        self.annotations.append(annotation)
        self.annotation_count = len(self.annotations)
        self._calculate_annotation_progress()
        self._updated_at = datetime.now()
        self._version += 1

    def _calculate_annotation_progress(self) -> None:
        """ì–´ë…¸í…Œì´ì…˜ ì§„í–‰ë¥  ê³„ì‚°"""
        if not self.pages:
            self.annotation_progress = 0.0
            return

        # ê°„ë‹¨í•œ ì§„í–‰ë¥  ê³„ì‚° (í˜ì´ì§€ë‹¹ ì–´ë…¸í…Œì´ì…˜ ì¡´ì¬ ì—¬ë¶€ ê¸°ì¤€)
        annotated_pages = sum(
            1 for page in self.pages if page.has_text or page.has_images
        )
        if annotated_pages == 0:
            self.annotation_progress = 0.0
        else:
            self.annotation_progress = min(self.annotation_count / annotated_pages, 1.0)

    def add_processing_history(self, operation: str, result: str, **kwargs) -> None:
        """
        ì²˜ë¦¬ ì´ë ¥ ì¶”ê°€

        Args:
            operation: ìˆ˜í–‰ëœ ì‘ì—…
            result: ì‘ì—… ê²°ê³¼
            **kwargs: ì¶”ê°€ ì •ë³´
        """
        history_entry = {
            "timestamp": datetime.now().isoformat(),
            "operation": operation,
            "result": result,
            **kwargs,
        }
        self.processing_history.append(history_entry)
        self.last_processed_time = datetime.now()
        self._updated_at = datetime.now()
        self._version += 1

    def get_processing_summary(self) -> Dict[str, Any]:
        """
        ì²˜ë¦¬ ìš”ì•½ ì •ë³´ ë°˜í™˜

        Returns:
            Dict[str, Any]: ì²˜ë¦¬ ìš”ì•½ ì •ë³´
        """
        return {
            "document_id": self.document_id,
            "file_path": self.file_path,
            "document_type": self.document_type.value,
            "document_status": self.document_status.value,
            "page_count": self.get_page_count(),
            "annotation_count": self.annotation_count,
            "annotation_progress": self.annotation_progress,
            "processing_operations": len(self.processing_history),
            "processing_errors": len(self.processing_errors),
            "validation_status": self.is_validated,
            "last_processed": (
                self.last_processed_time.isoformat()
                if self.last_processed_time
                else None
            ),
            "creation_time": self.created_at.isoformat(),
            "last_updated": self.updated_at.isoformat(),
        }

    def clone(self) -> "DocumentModel":
        """
        ë¬¸ì„œ ëª¨ë¸ ë³µì œ

        Returns:
            DocumentModel: ë³µì œëœ ë¬¸ì„œ ëª¨ë¸
        """
        cloned_dict = self.to_dict()
        cloned_dict["document_id"] = str(uuid.uuid4())  # ìƒˆë¡œìš´ ID ìƒì„±
        return self.from_dict(cloned_dict)

    def __str__(self) -> str:
        """ë¬¸ìì—´ í‘œí˜„"""
        return f"DocumentModel(id={self.document_id}, file={self.metadata.file_name}, pages={self.get_page_count()})"

    def __repr__(self) -> str:
        """ê°œë°œììš© í‘œí˜„"""
        return (
            f"DocumentModel("
            f"document_id='{self.document_id}', "
            f"file_path='{self.file_path}', "
            f"document_type={self.document_type.name}, "
            f"page_count={self.get_page_count()}, "
            f"annotation_count={self.annotation_count}"
            f")"
        )


# ====================================================================================
# 5. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
# ====================================================================================


def create_document_from_file(file_path: str) -> DocumentModel:
    """
    íŒŒì¼ì—ì„œ ë¬¸ì„œ ëª¨ë¸ ìƒì„±

    Args:
        file_path: íŒŒì¼ ê²½ë¡œ

    Returns:
        DocumentModel: ìƒì„±ëœ ë¬¸ì„œ ëª¨ë¸
    """
    return DocumentModel.from_file_path(file_path)


def validate_document_batch(documents: List[DocumentModel]) -> Dict[str, Any]:
    """
    ë¬¸ì„œ ë°°ì¹˜ ê²€ì¦

    Args:
        documents: ê²€ì¦í•  ë¬¸ì„œ ëª©ë¡

    Returns:
        Dict[str, Any]: ë°°ì¹˜ ê²€ì¦ ê²°ê³¼
    """
    results = {
        "total_documents": len(documents),
        "valid_documents": 0,
        "invalid_documents": 0,
        "validation_errors": [],
        "validation_warnings": [],
    }

    for doc in documents:
        is_valid = doc.validate()
        if is_valid:
            results["valid_documents"] += 1
        else:
            results["invalid_documents"] += 1
            results["validation_errors"].extend(doc.validation_errors)
            results["validation_warnings"].extend(doc.validation_warnings)

    return results


def merge_document_statistics(documents: List[DocumentModel]) -> DocumentStatistics:
    """
    ë‹¤ì¤‘ ë¬¸ì„œ í†µê³„ ì •ë³´ ë³‘í•©

    Args:
        documents: ë¬¸ì„œ ëª©ë¡

    Returns:
        DocumentStatistics: ë³‘í•©ëœ í†µê³„ ì •ë³´
    """
    merged_stats = DocumentStatistics()

    # ëª¨ë“  í˜ì´ì§€ ì •ë³´ ìˆ˜ì§‘
    all_pages = []
    for doc in documents:
        all_pages.extend(doc.pages)

    # í†µê³„ ê³„ì‚°
    merged_stats.calculate_statistics(all_pages)

    return merged_stats


if __name__ == "__main__":
    # ë¬¸ì„œ ëª¨ë¸ í…ŒìŠ¤íŠ¸
    print("YOKOGAWA OCR ë¬¸ì„œ ëª¨ë¸ í…ŒìŠ¤íŠ¸")
    print("=" * 50)

    try:
        # í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ íŒŒì¼ ìƒì„± (ì‹¤ì œ ì‚¬ìš© ì‹œì—ëŠ” ì‹¤ì œ íŒŒì¼ ê²½ë¡œ ì‚¬ìš©)
        test_file_path = "test_document.pdf"

        # ë”ë¯¸ íŒŒì¼ì´ ì—†ìœ¼ë©´ í…ŒìŠ¤íŠ¸ ìŠ¤í‚µ
        if not os.path.exists(test_file_path):
            print("âš ï¸  í…ŒìŠ¤íŠ¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ì‹¤ì œ íŒŒì¼ ê²½ë¡œë¥¼ ì‚¬ìš©í•˜ì—¬ í…ŒìŠ¤íŠ¸í•˜ì„¸ìš”.")
        else:
            # ë¬¸ì„œ ëª¨ë¸ ìƒì„±
            document = DocumentModel.from_file_path(test_file_path)
            print(f"âœ… ë¬¸ì„œ ëª¨ë¸ ìƒì„± ì™„ë£Œ: {document.document_id}")

            # ê²€ì¦ ìˆ˜í–‰
            is_valid = document.validate()
            print(f"âœ… ë¬¸ì„œ ê²€ì¦ ê²°ê³¼: {'í†µê³¼' if is_valid else 'ì‹¤íŒ¨'}")

            # ìš”ì•½ ì •ë³´ ì¶œë ¥
            summary = document.get_processing_summary()
            print(f"ğŸ“Š ë¬¸ì„œ ìš”ì•½: {summary}")

    except Exception as e:
        print(f"âŒ ë¬¸ì„œ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

    print("\nğŸ¯ ë¬¸ì„œ ëª¨ë¸ êµ¬í˜„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
